{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bias Variance Tradeoff\n",
    "\n",
    "Setting: The basic linear regression model requires that the relation between dependent and independent variable is linear. In reality there are situations where the relationship is more complex. In these cases a simple linear regression model will not be able to capture the underlying data of the model.\n",
    "\n",
    "Solution: We conduct a polynomial regression with quadratic, cubic or even higher degree curves. These polynomial regressions lead to models which exhibit the following problems.\n",
    "\n",
    "Bias: The inability of a machine learning algorithm like linear regression to predict the real relationship within a dataset. So the bias gives a meassure between the average prediction of our model and the correct value which we are trying to predict. A model with a high bias oversimplifies the underlying problem, the so called underfitting.\n",
    "\n",
    "Variance: Variance is the variability of model prediction for a given data point or a value. With higher variance the model gets more flexibility to adopt to the training data, which leads to the problem of so called overfitting. When testet on the test set the model fails because it is not able to generalize on data it has not seen before.\n",
    "\n",
    "The solution to that problem is the bias variance tradeoff. It is a property of all machine learning models that enforces a tradeoff between how \"flexible\" the model is and how well it performs on unseen data.\n",
    "\n",
    "There are three possible cases:\n",
    "1. An underfit with high bias and low variance\n",
    "2. A correct fit with low bias and low variance\n",
    "3. An overfit with low bias and high variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bias Variance Tradeoff Second Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build an effective machine learning model, it is important to find the right balance between bias and variance. In case of a prediction model, bias and variance correspond to the two types of prediction errors.\n",
    "\n",
    "The term bias refers to the the difference between the average predictions of our model and the correct values we are tying to predict. Models with high bias oversimplyfy the real model so to say which leads prediction errors on training and test data. The model suffers from underfitting\n",
    "\n",
    "Variance on the other hand refers to the variability of the model predictions. Models with high variance pay too much attention to the training data and do not generalize. This leads to models that perform very well on training data but fail on test data because they cannot generalize on data they have not seen before. Models with high variance therefore overfit.\n",
    "\n",
    "In supervised learning underfitting happens when a model is not able to understand the underlying pattern of the data. It therefore exhibits high bias and low variance. This could for instance happen if we tried to build a linear model with nonlinear data (linear regression vs. polynomial regression)\n",
    "\n",
    "Overfitting happens when our model captures the noise in the underlying model in an attempt to find a perfect fit to the training data. As soon as these models are used on the test set they fail.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
