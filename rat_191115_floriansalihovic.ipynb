{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _Bias Variance tradeoff_ is a concept to understand that whenever we train a machine with data to make predictions, we have to make tradeoffs in the way we use the data to create a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could either use a very simplistic model, which takes only very few features into account to make a prediction. This approach leads to _underfitting_. The higher the bias, the higher the error on training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could model a very complex model which fits the traininig data perfectly. The consequence is an _overfitted_ model, which most likely only performs well on the training data but very bad on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tradeoff basically describes the scenario when a model can be over- or underfitted. Using the _Bias-Variance Tradeoff_ we try to identify/find a model, which has a low error on training- and testdata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attempting to predict the prices of houses in a specific area, a model could be designed to fit the data perfectly. But every prediction would be off, as every test data point could be very different from the training data. The assumptions on which the model is based would translate to: I exactly know the state of the real world and can make very specific predictions. This leads to a high variance when testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different approach would be to only use the average (or a very generalized line of best fit). The model would not be really useful, as the assumptions would be oversimplified. Any attempt to predict would be off, as every observation with all of its features is very unique in its nature (by assumption)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attempt to find da good _simply-enough_ model, which has an acceptable error rate on training and test data leads to the _Bias-Variance Tradeoff_ - the insight that _under-_ as well as _overfitting_ can happend quite fast and we have to understand that comparing/measuring the errors of models is part of Data Scientists (m|f|d) daily business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "- [Understanding The Bias-Variance Tradeoff, Seema Singh\n",
    " (Rev.: 165e6942b229)](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
