{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Buisness Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buisness setting\n",
    "- Problem Statement\n",
    "- Buisness Value\n",
    "- knowing ressources (time, people, finances, energy/priorisation)\n",
    "- equipment\n",
    "- metric of success\n",
    "\n",
    "how?\n",
    "- what other data scientists have done\n",
    "- ask the stakeholder\n",
    "- own research\n",
    "- company website\n",
    "- competitor websites\n",
    "- company wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *.csv, *.json\n",
    "- SQL -> to get data from database\n",
    "- PySpark\n",
    "- webscraping\n",
    "\n",
    "\n",
    "- get your data from different sources\n",
    "- try to understand what data you got "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial look:\n",
    "- understanding features of the data\n",
    "    - column names, predictor and independent variables\n",
    "    - taking a look at rows (=observations/sample)\n",
    "- shape/size of the data (Enough data available?)\n",
    "    - If not ask for more data or syntethic data generation\n",
    "    - If too large: Should we random sample?\n",
    "- is data loaded correctly? \n",
    "- Do we have multiple datasets?\n",
    "    -If yes, combine them, truncate them, modify them\n",
    "- checking datatype (numerical, categorical, same scale(timezone, currencies))\n",
    "- check for conventions\n",
    "- missing values (Nan, empty or like ?)\n",
    "- checking for duplicates\n",
    "    - remove double entris\n",
    "- checking data for inconsistences (neaming conventions)\n",
    "    - cleaning conventions\n",
    "- checking the data types and removing data type inconsistences\n",
    "    - same scale (same timezone, same currency)\n",
    "- check for relevancy of data with respect to problem statement \n",
    "- check for sub/additional datasets (say complete project info is found in them)\n",
    "\n",
    "after initial look:\n",
    "- rename, removing whitespaces/characters\n",
    "- if the feature is a string and we know it should be a date, we convert it\n",
    "- handle missing values\n",
    "    - inpute mean\n",
    "    - delete rows\n",
    "    - enter a dummy\n",
    "    - talk to the buisness\n",
    "- shape/size\n",
    "    - if to small: ask for more data, synthetic data generation, look for similar data from different data sources\n",
    "    - if to large: take a random samples after cleaning and exploration\n",
    "        - columns: do PCA\n",
    "- is data loaded correctly?\n",
    "    - depending on initial look we convert the feature values to values that makes sense\n",
    "- do we have multiple datasets?\n",
    "    - find relationships between datasets and combine them\n",
    "- checking datatype?\n",
    "    - to datetime convert string to pandas timestamp\n",
    "    - create dummies for categorial variables\n",
    "    - change object to numeric\n",
    "- duplicates?\n",
    "    - remove duplicates\n",
    "- checking data for inconsistences (neaming conventions)\n",
    "    - try to understand, clean it and articulate it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trying to understand the patterns and bias in the data\n",
    "- 'Brainstorming'\n",
    "- special focus on the dependency between all single features in X and y\n",
    "- identifying outliers\n",
    "- identifying the correlations between features\n",
    "    - checking for multi-collinearity\n",
    "\n",
    "- summary statistics: tells us distribution of numerical features\n",
    "- visualise the distributions of numerical features\n",
    "- plot the categorial variable distributions by barplots, pieplots\n",
    "- explore target of predicted variable relationship with predictor variable one at a time with scatterplots\n",
    "- check for outliers from distribution plots\n",
    "- check for normality\n",
    "- make advanced plots to dive deeper into understanding the various features their relationships amongst each other and with the predicted variables \n",
    "- histogram of the target, to get an better understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the process of using domain knowledge to transform your raw data into informative features that represent the business problem you are trying to solve\n",
    "- transforming skewed continous variables to normally distributed variables\n",
    "- looking for features in features (gender from name)\n",
    "- scaling (min-max scaler, standard scaler)\n",
    "- create new categories \n",
    "    - binning numeric variables into categorical\n",
    "    - Regrouping old categories to create new categories\n",
    "- dummy variables for categories we want to use\n",
    "- dimensiondity reduction, PCA\n",
    "- impute values for features (this can be a part of data cleaning as well as feature engineering)\n",
    "- apply weights to features denoting feature importance\n",
    "- drop features we don't need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick models to use that are appropiate for the current challanges\n",
    "- train test split\n",
    "- balance the dataset\n",
    "- what is the baseline\n",
    "- run the model\n",
    "    - pca variables\n",
    "    - k-fold-cross validation\n",
    "    - gridsearch\n",
    "- improve the model by tuning the hyperparameter\n",
    "- evaluate model performance \n",
    "    - confusion matrix\n",
    "    - classification report\n",
    "- based on pre determand metric of sucess from buisness understanding which of evaluation matrix are most appropiate for our models (accurancy, precision, recall...)\n",
    "- compare models (at least 3 ideally) against evaluation metrics\n",
    "- identifying the most important predictors across all models created\n",
    "- hypotheses testing for marketing/sales/healtcate domains\n",
    "- visualize model based on most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make a function for plotting your findings, to be able to make easy comparable plots\n",
    "- make insightfull plots that visualize your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start all over again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main takeaways from the last project\n",
    "- structure your workflow \n",
    "- try to not get lost in one part of the Data Science Lifecycle\n",
    "- run trough it in time to figure out, where you have to improve and spend more time on\n",
    "- if you have a huge dataset, work with a sample first to be able to go trough the Lifecycle in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
