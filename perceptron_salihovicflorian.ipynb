{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAT - Artifical Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Florian Salihovic, 11/29/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Definition Perceptron___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perception is a metaphor for a neuron in the brain. Technically it is a function which takes an input and calculates an out put based on the input. Additionally, weights and biases are additional values to be taken into account. One perceptron makes up a one dimensional neural network. In a neural network with multiple layers, the output of one perception will be the input for other perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Activation function___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An activation function is the function which calculates the output based on the inputs, weights and the bias. In principle, each perceptron could use its own activation function.\n",
    "\n",
    "Examples for activation functions\n",
    "- Sigmoid\n",
    "- Tanh\n",
    "- ReLU\n",
    "- Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links\n",
    "- [wikipedia: activation function](https://en.wikipedia.org/wiki/Activation_function)\n",
    "- [wikipedia: Sigmoid](https://en.wikipedia.org/wiki/Logistic_function)\n",
    "- [wikipedia: Tanh](https://en.wikipedia.org/wiki/Hyperbolic_function#Tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Error function___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error function calculates the difference between the expected- and the actual output. The error function is used to adjust the weights of the neural network recursively, attempting the enhance the neural networks accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links\n",
    "- [wikipedia: rectifier (Softplus, Leaky ReLUs and more)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Weights and bias___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights and bias are necessary for a single perceptron to specialize in a task. In image recognition for example, the recognition of shapes like eyes, noses etc. are done by a layer of specialized perceptrons while other layers are responsible for recognizing the shape of a face. The bias is usually a constant value in a neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
